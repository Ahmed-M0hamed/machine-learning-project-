{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from PIL import Image \nimport os \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport pandas as pd \nimport tensorflow as tf \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load the data","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/hubmap-organ-segmentation/train.csv')\ntest_data = pd.read_csv('../input/hubmap-organ-segmentation/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data.img_width.unique())\nprint(train_data.img_height.unique())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = tf.data.Dataset.list_files('../input/hubmap-organ-segmentation/train_images/*.tiff')\ntest_images = tf.data.Dataset.list_files('../input/hubmap-organ-segmentation/test_images/*.tiff')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the rle of the training data \ntrain_rle_arr= np.array(train_data.rle) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_rle = tf.data.Dataset.from_tensor_slices(train_rle_arr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.zip((train_images , train_rle))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert rle to mask \ndef interpret_rle(rle , width , target_size ):\n    rle_arr= np.array(rle.split() , dtype = int)\n    # get start of each annotation \n    start = rle_arr[::2] \n    steps = rle_arr[1::2] \n    end = start + steps\n    width , width = width\n    img = np.zeros(shape = (width * width ))\n    for st , en in zip(start ,end) : \n        img[st : en] = 1 \n    \n    img = Image.fromarray(img.reshape(width, width))\n    \n    img = img.resize((target_size, target_size))\n    img = np.array(img).astype(float)\n    #rescale label\n    img = np.round((img - img.min())/(img.max() - img.min()))\n    \n    return img.T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# preprocess the dataset\n","metadata":{}},{"cell_type":"code","source":"\ndef preprocess(train_image_path , rle) : \n    # load the train images \n    train_img = Image.open(train_image_path.numpy()) \n    # get the mask \n    mask_img = interpret_rle(rle.numpy() , train_img.size  , 128 )\n    mask_img = np.expand_dims(mask_img , -1)\n    # resize and rescale the images \n    train_img = train_img.resize((128 , 128 )) \n    train_img = np.array(train_img )\n    train_img = train_img / 255. \n    mask_img = mask_img / 255. \n    return train_img , mask_img ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# data augmention\n","metadata":{}},{"cell_type":"code","source":"# augment the data with fixed seed to get the same changes for both the image and mask \nclass Augment(tf.keras.layers.Layer) : \n    def __init__(self , seed = 42) : \n        super().__init__()\n        self.flip_inputs = tf.keras.layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=seed)\n        self.flip_labels = tf.keras.layers.RandomFlip(mode=\"horizontal_and_vertical\", seed=seed)\n        self.rotate_inputs = tf.keras.layers.RandomRotation(.2 , seed=seed)\n        self.rotate_labels = tf.keras.layers.RandomRotation(.2 , seed = seed)\n    def call(self , inputs , labels)  :\n        X = self.flip_inputs(inputs)\n        y = self.flip_labels(labels)\n        X = self.rotate_inputs(X)\n        y = self.rotate_labels(y)\n        return X  , y \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(lambda x , y : tf.py_function(preprocess, [x , y], [tf.float32 , tf.float32]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.cache().shuffle(200).batch(8).map(Augment()).prefetch(4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the data \ntrain_dataset = dataset.take(38)\nval_dataset  = dataset.skip(38)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# the model \n\n## the U-net model","metadata":{}},{"cell_type":"code","source":"def conv_block(X , n_filters , pooling = True ) : \n    X = tf.keras.layers.Conv2D(n_filters , (3,3) , padding='same' , activation ='relu')(X)\n    X =  tf.keras.layers.Conv2D(n_filters , (3,3) , padding='same' , activation ='relu')(X)\n    if pooling : \n        P = tf.keras.layers.MaxPooling2D((2,2))(X) \n        P = tf.keras.layers.Dropout(.3)(P)\n        return P , X\n    return X \ndef conv_transpose_block(X , skip_connection , n_filters ): \n    X_t = tf.keras.layers.Conv2DTranspose(n_filters , (3,3) , strides=(2,2) , activation='relu' , padding ='same')(X)\n    X_t = tf.keras.layers.Concatenate()([X_t , skip_connection])\n    return conv_block(X_t , n_filters , pooling = False ) \n\ndef Model(input_shape) : \n    X = tf.keras.layers.Input(input_shape)\n    P , skip_1 = conv_block(X , 64)\n    P , skip_2 = conv_block(P , 128)\n    P , skip_3 = conv_block(P , 256)\n    P , skip_4 = conv_block(P , 512)\n    \n    bottle_nick  = conv_block(P , 1024 , pooling = False )\n    \n    T = conv_transpose_block(bottle_nick , skip_4 , 512)\n    T = conv_transpose_block(T , skip_3 , 256)\n    T = conv_transpose_block(T , skip_2 , 128)\n    T = conv_transpose_block(T , skip_1 , 64)\n    \n    out = tf.keras.layers.Conv2D(2, (1,1) , padding ='same' , activation='softmax')(T) \n    \n    return tf.keras.Model(X  , out )\n    \n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import backend as K\ndef dice_coef(y_true, y_pred, smooth=1):\n    # flatten\n    y_true_f = K.flatten(K.cast(y_true, np.float32))\n    #y_pred_f = K.flatten(K.cast(K.argmax(y_pred, axis=-1), np.float32))\n    y_pred_f = K.flatten(K.cast(K.argmax(y_pred, axis=-1), np.float32))\n    # compute numerator and denominator\n    intersection = K.sum(y_true_f * y_pred_f)\n    union = K.sum(y_true_f) + K.sum(y_pred_f)\n    # apply dice formula\n    dice = K.mean((2.*intersection + smooth)/(union + smooth))\n    return dice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model((128 ,128 , 3))\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy' , dice_coef])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True, rankdir='TB')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 20\n\nmodel_history = model.fit(train_dataset, epochs=EPOCHS,\n                         validation_data=val_dataset )","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}